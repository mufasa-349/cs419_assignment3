
% CS419 Assignment #3 Report (IEEE double-column)
% Compile: pdflatex cs419_assignment3_report.tex  (twice for refs if needed)

\documentclass[conference]{IEEEtran}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{microtype}

\title{Instance Segmentation of Microscopy Cells Using Marker-Based Watershed}

\author{
\IEEEauthorblockN{Mustafa Bozyel (Student ID: 32417)}
\IEEEauthorblockA{Sabanci University, CS419 Digital Image and Video Analysis\\
Email: mustafa.bozyel@sabanciuniv.edu}
}

\begin{document}
\maketitle

\begin{abstract}
This report presents a non-deep-learning instance segmentation pipeline for microscopy cell images. The goal is to output a grayscale label image where each cell is assigned a unique integer value and background is set to zero. We adopt a marker-based watershed transform with distance-transform-driven markers to handle touching cells. We also analyze the effect of key parameters (thresholding, morphology, marker extraction) on segmentation performance measured by pixel-level F1 and IoU.
\end{abstract}

\begin{IEEEkeywords}
segmentation, watershed, distance transform, microscopy, instance labeling
\end{IEEEkeywords}

\section{Task Definition}
Given a microscopy color image, the required output is a grayscale image of the same size in which each cell has a different scalar label (1..N) and the background is 0. The method must be implemented from scratch and must rely on at least one segmentation technique treated in class, without using deep learning.

\section{Method Selection and Rationale}
\subsection{Chosen Method}
We choose \textbf{marker-based watershed} as the core segmentation approach, combined with the \textbf{distance transform} to resolve \emph{touching objects}. The watershed transform is a morphological segmentation tool that floods a topographic surface from minima. When applied directly on gradient images it tends to over-segment due to many local minima; marker-based watershed addresses this by constraining the flooding sources to user-defined markers, making the number of markers correspond to the number of regions.

\subsection{Why Marker-Based Watershed Fits Cell Images}
Microscopy cell images often contain:
(i) non-uniform intensity,
(ii) small debris/noise,
(iii) clusters of touching cells.
The distance transform turns a binary foreground mask into a smooth surface that peaks at cell centers, providing reliable internal markers. Watershed then places boundaries along high-gradient ridges between markers, which is well-suited for separating adjacent cells.

\subsection{Why Other Methods Were Not Chosen}
We considered the main categories covered in the course segmentation lecture:
\begin{itemize}
\item \textbf{Histogram/thresholding-only methods:} Fast, but extremely sensitive to illumination and threshold choice, and do not separate touching cells reliably.
\item \textbf{Clustering (k-means, mean-shift):} k-means requires selecting $K$ (often unknown), and both approaches can ignore spatial continuity unless coordinates are added; they can also merge nearby cells with similar colors.
\item \textbf{Region growing/splitting:} Requires seed selection and similarity criteria; results can be unstable under noise and intensity variation, and splitting (quadtree) can be blocky.
\item \textbf{Graph partitioning (normalized cuts):} Robust but computationally heavy and requires decisions about stopping criteria and graph construction.
\end{itemize}
Given the dataset difficulty and the need to separate touching cells, marker-based watershed provides a strong accuracy/computation trade-off.

\section{Pipeline}
Our end-to-end pipeline is summarized below.
\subsection{Automatic Image Type Detection}
To handle diverse microscopy image types (e.g., bright cells on dark background vs. dark cells on bright background), we implement an automatic invert detection mechanism. The algorithm analyzes the histogram of the feature channel after preprocessing:
\begin{enumerate}
\item Compute the intensity histogram of the feature image.
\item Calculate the ratio of dark pixels (intensity $< 85$) and bright pixels (intensity $> 170$).
\item If dark pixels dominate ($> 30\%$ of total and exceed bright pixels), the image likely has a dark background with bright cells, so we set the invert parameter to false.
\item Otherwise, we assume bright background with dark cells and set the invert parameter to true (default).
\end{enumerate}
This automatic detection eliminates the need for manual parameter tuning when processing mixed datasets and ensures robust performance across different microscopy imaging conditions.

\subsection{Preprocessing and Foreground Mask}
\begin{enumerate}
\item Convert image to an informative single-channel feature map (default: grayscale; optional: LAB/HSV channels).
\item Contrast enhancement using CLAHE (optional).
\item Denoising with Gaussian blur.
\item \textbf{Automatic invert detection} (if enabled): Analyze histogram to determine whether cells are brighter or darker than background.
\item Foreground/background separation via Otsu thresholding (or adaptive thresholding for uneven illumination), using the automatically detected or manually specified invert setting.
\item Morphological opening to remove small noise; optional closing to fill small holes.
\end{enumerate}

\subsection{Marker Extraction via Distance Transform}
\begin{enumerate}
\item Compute the distance transform on the binary foreground mask.
\item Compute \emph{sure foreground} by thresholding the distance map:
\[
\text{sure\_fg} = \mathbf{1}\left( D(x,y) > \alpha \cdot \max(D) \right)
\]
where $\mathbf{1}(\cdot)$ is the indicator function and $\alpha$ is a tunable parameter.
\item Compute \emph{sure background} by dilating the foreground mask.
\item Define the \emph{unknown region} as sure\_bg minus sure\_fg.
\item Create connected-components markers from sure\_fg and set unknown pixels to 0.
\end{enumerate}

\subsection{Watershed and Instance Label Output}
We apply watershed on the original image with the computed markers. The output is converted into an instance label image:
background $\rightarrow 0$, and each region label $\rightarrow 1..N$. Tiny regions are filtered and remaining labels are re-indexed to be consecutive.

\section{Parameters and Their Effects}
Table~\ref{tab:params} lists the main parameters in our implementation. Their effects are summarized afterwards.

\begin{table*}[t]
\caption{Key parameters of the watershed pipeline.}
\label{tab:params}
\centering
\small
\begin{tabular}{@{}p{3.5cm}p{10cm}@{}}
\toprule
Parameter & Effect / trade-off \\ \midrule
Feature channel & Drives separability of cells vs background \\
Auto invert detection & Automatically determines if cells are brighter/darker than background \\
Invert threshold & Manual override if auto-detection fails \\
CLAHE (clip, tile) & Enhances local contrast; too high amplifies noise \\
Blur kernel & Reduces noise; too high removes thin boundaries \\
Threshold method & Otsu (global) vs adaptive (uneven illumination) \\
Morph kernel, open/close iters & Removes noise / fills holes; too aggressive erodes cells \\
Distance threshold $\alpha$ & Controls number/size of internal markers \\
Background dilation iters & Controls unknown region size \\
Min area & Removes spurious tiny segments \\ \bottomrule
\end{tabular}
\end{table*}

\subsection{Most Sensitive Parameters}
\textbf{Distance threshold $\alpha$:} Low $\alpha$ produces many markers (risk of over-segmentation). High $\alpha$ may miss markers in weak/low-contrast cells (under-segmentation).

\textbf{Morphological opening:} Too little opening keeps debris (false positives). Too much opening breaks thin cell regions (false negatives) and reduces marker quality.

\textbf{Thresholding mode:} Otsu works best under relatively consistent illumination. Adaptive thresholding can help when illumination varies, but may create fragmented masks in texture-heavy regions.

\subsection{Recommended Starting Values}
Based on qualitative validation and standard practice for distance-transform watershed:
\begin{itemize}
\item $\alpha \in [0.40, 0.55]$ (default 0.45)
\item Morph kernel size $k \in \{3,5\}$, opening iterations 1--3
\item CLAHE clipLimit $\in [1.5, 3.0]$, tile size 8
\item Blur kernel 3--7
\item Min area 100--300 pixels (dataset dependent)
\end{itemize}
The truly optimal values should be selected by grid search on a small validation subset (e.g., 10 images), maximizing pixel-level F1 and IoU.

\section{Evaluation Protocol}
We report pixel-level (binary) F1 and IoU by comparing predicted foreground ($\hat{Y} > 0$) with ground-truth foreground ($Y > 0$). For each test image, we compute:
\[
\text{IoU}=\frac{TP}{TP+FP+FN}, \quad
F1=\frac{2TP}{2TP+FP+FN}.
\]
\textbf{Note:} The assignment requires instance-labeled outputs; however, the provided evaluation metric is pixel-level, so we treat the task as foreground-vs-background for scoring.

\section{Results and Discussion}
\subsection{Test Dataset}
We evaluated our method on 26 diverse microscopy images from the dataset, including:
\begin{itemize}
\item \textbf{Cell series:} cell\_00966 through cell\_00988 (23 images)
\item \textbf{BMP images:} bmp-img1, bmp-img2, bmp-img3 (3 images)
\end{itemize}
These images exhibit varying characteristics: different cell densities, illumination conditions, background types (dark vs. bright), and cell morphologies. The automatic invert detection successfully handled both dark-background and bright-background images without manual intervention.

\subsection{Quantitative Results}
Table~\ref{tab:results} summarizes the number of detected instances for a subset of test images. Note that without ground-truth labels, we report instance counts as a proxy for segmentation performance.

\begin{table}[t]
\caption{Instance counts for selected test images.}
\label{tab:results}
\centering
\begin{tabular}{@{}lc@{}}
\toprule
Image & Detected Instances \\ \midrule
cell\_00966 & 42 \\
cell\_00967 & 119 \\
cell\_00968 & 151 \\
cell\_00969 & 29 \\
cell\_00970 & 89 \\
cell\_00971 & 13 \\
cell\_00972 & 134 \\
cell\_00973 & 92 \\
cell\_00974 & 124 \\
cell\_00975 & 53 \\
cell\_00976 & 67 \\
cell\_00977 & 43 \\
cell\_00978 & 54 \\
cell\_00979 & 111 \\
cell\_00980 & 35 \\
bmp-img1 & 24 \\
bmp-img2 & 29 \\
bmp-img3 & 39 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Qualitative Results}
We present qualitative results showing both successful segmentations and failure cases. Figures show the original image, the segmentation overlay with green watershed borders, and the instance label visualization.

\subsubsection{Successful Cases}
Figure~\ref{fig:success1} shows a well-segmented image with clear cell boundaries. The method successfully separates touching cells and correctly identifies individual cell instances.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00969.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00969_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00969_pred_visualized.png}
\caption{Successful segmentation example (cell\_00969): Original image (left), segmentation overlay with borders (center), and color-coded instance labels (right) showing 29 detected instances.}
\label{fig:success1}
\end{figure}

Figure~\ref{fig:success2} demonstrates robust performance on images with high cell density. Despite many touching cells, the distance-transform markers effectively separate individual instances.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00968.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00968_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00968_pred_visualized.png}
\caption{High-density cell image (cell\_00968): Original (left), borders overlay (center), and instance labels (right) with 151 detected instances.}
\label{fig:success2}
\end{figure}

Figure~\ref{fig:success3} shows successful handling of dark-background images with bright cells, where automatic invert detection correctly identified the image type.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00971.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00971_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00971_pred_visualized.png}
\caption{Dark-background image (cell\_00971): Original (left), borders overlay (center), and instance labels (right) with 13 detected instances. Automatic invert detection handled this case correctly.}
\label{fig:success3}
\end{figure}

\subsubsection{Failure Cases}
Figure~\ref{fig:failure1} illustrates a case of under-segmentation where some cells are merged together. This occurs when the distance transform threshold is too high, resulting in insufficient markers.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00987.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00987_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00987_pred_visualized.png}
\caption{Under-segmentation case (cell\_00987): Original (left), borders (center), and instance labels (right) showing only 9 instances detected. Some cells are merged due to insufficient markers from distance transform.}
\label{fig:failure1}
\end{figure}

Figure~\ref{fig:failure2} shows over-segmentation where noise or artifacts are incorrectly identified as cells, leading to false positive detections.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00967.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00967_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00967_pred_visualized.png}
\caption{Over-segmentation case (cell\_00967): Original (left), borders (center), and instance labels (right) showing 119 instances detected. Some may be noise artifacts. The high density and complex morphology challenge the method.}
\label{fig:failure2}
\end{figure}

Figure~\ref{fig:failure3} demonstrates a challenging case with very low contrast between cells and background, where thresholding struggles to create a reliable binary mask.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00986.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00986_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00986_pred_visualized.png}
\caption{Low-contrast challenge (cell\_00986): Original (left), borders (center), and instance labels (right) showing only 19 instances detected. Low contrast between cells and background makes thresholding unreliable.}
\label{fig:failure3}
\end{figure}

Figure~\ref{fig:failure4} shows a case where the method struggles with irregular cell shapes and varying sizes, leading to missed detections.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img2.jpeg}
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img2_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img2_pred_visualized.png}
\caption{Irregular morphology (bmp-img2): Original (left), borders (center), and instance labels (right) showing 29 instances detected. Irregular cell shapes and size variations challenge the distance-transform marker extraction.}
\label{fig:failure4}
\end{figure}

Figure~\ref{fig:success4} demonstrates another successful case with well-separated cells and good contrast.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00975.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00975_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00975_pred_visualized.png}
\caption{Well-separated cells (cell\_00975): Original (left), borders (center), and instance labels (right) with 53 detected instances. Good cell separation and contrast.}
\label{fig:success4}
\end{figure}

Figure~\ref{fig:success5} shows successful segmentation on a BMP format image with moderate cell density.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img1.jpeg}
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img1_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/bmp-img1_pred_visualized.png}
\caption{BMP format image (bmp-img1): Original (left), borders (center), and instance labels (right) with 24 detected instances. Method handles different image formats well.}
\label{fig:success5}
\end{figure}

Figure~\ref{fig:success6} illustrates robust performance on images with varying cell sizes.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00973.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00973_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00973_pred_visualized.png}
\caption{Varying cell sizes (cell\_00973): Original (left), borders (center), and instance labels (right) with 92 detected instances. Method handles size variations reasonably well.}
\label{fig:success6}
\end{figure}

Figure~\ref{fig:failure5} shows a challenging case with very high cell density where some cells are missed.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00972.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00972_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00972_pred_visualized.png}
\caption{Very high density (cell\_00972): Original (left), borders (center), and instance labels (right) showing 134 instances detected. Extreme density leads to some missed detections and boundary placement errors.}
\label{fig:failure5}
\end{figure}

Figure~\ref{fig:success7} demonstrates the instance label visualization, showing how each cell receives a unique label.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00970.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00970_vis.png}
\includegraphics[width=0.32\columnwidth]{test-cases/cell_00970_pred_visualized.png}
\caption{Instance label visualization (cell\_00970): Original image (left), borders overlay (center), and color-coded instance labels (right). Each cell has a unique integer label (1--89).}
\label{fig:success7}
\end{figure}

\subsection{Failure Modes and Analysis}
Based on our evaluation of 26 test images, we identified the following failure modes:

\begin{itemize}
\item \textbf{Severe under-segmentation:} Occurs when distance transform threshold $\alpha$ is too high, resulting in insufficient markers (e.g., cell\_00987 with only 9 instances). \textbf{Solution:} Lower $\alpha$ to 0.35--0.40, reduce morphological opening iterations, or try a different feature channel (e.g., LAB-A or HSV-S) for better contrast.

\item \textbf{Over-segmentation:} Too many markers due to noise or artifacts being interpreted as cells (e.g., cell\_00967 with 119 instances). \textbf{Solution:} Increase Gaussian blur kernel size, increase morphological opening iterations, increase $\alpha$ to 0.50--0.55, or reduce CLAHE clipLimit.

\item \textbf{Low-contrast failures:} When cells and background have similar intensities, thresholding produces unreliable binary masks (e.g., cell\_00986). \textbf{Solution:} Switch to adaptive thresholding, use a different color channel (HSV-S or LAB-L), or increase CLAHE strength.

\item \textbf{Irregular morphology:} Cells with highly irregular shapes or large size variations challenge the distance-transform approach (e.g., bmp-img2). \textbf{Solution:} Adjust min\_area filter, use multi-scale distance transform, or combine with region-growing from markers.
\end{itemize}

\subsection{When the Method Performs Well}
The method excels in the following scenarios:
\begin{itemize}
\item \textbf{Clear cell boundaries:} When cells have distinct edges and good contrast with background (e.g., cell\_00969, cell\_00968).
\item \textbf{Moderate cell density:} Not too sparse (few markers) nor too dense (marker confusion), typically 20--100 cells per image.
\item \textbf{Uniform illumination:} Consistent lighting allows Otsu thresholding to work effectively.
\item \textbf{Regular cell shapes:} Round or elliptical cells produce reliable distance-transform peaks for marker extraction.
\item \textbf{Automatic invert detection:} Successfully handles both dark-background (bright cells) and bright-background (dark cells) images without manual tuning.
\end{itemize}

\subsection{When the Method Performs Poorly}
The method struggles in these cases:
\begin{itemize}
\item \textbf{Very low contrast:} When cell-background contrast is minimal, thresholding fails regardless of method.
\item \textbf{Extreme cell density:} Very dense clusters (150+ cells) lead to marker confusion and boundary placement errors.
\item \textbf{Highly irregular shapes:} Non-convex or elongated cells produce weak or multiple distance-transform peaks.
\item \textbf{Severe noise:} High noise levels corrupt the binary mask and distance transform, leading to spurious markers.
\item \textbf{Variable illumination:} Strong gradients or shadows require adaptive thresholding, which can fragment the mask.
\end{itemize}

\section{Conclusion}
Marker-based watershed with distance-transform markers provides a practical and explainable non-DL solution for microscopy cell instance segmentation, especially when touching cells are common. The methodâ€™s performance is governed mainly by marker quality; thus, parameter tuning should focus on thresholding, morphology, and the distance threshold controlling internal markers.

\section*{Reproducibility}
All code is provided in the file \texttt{watershed\_cellseg.py}. For batch evaluation:
\begin{verbatim}
python watershed_cellseg.py --img_dir images/ --label_dir labels/ \
  --out_dir preds/ --eval
\end{verbatim}
The automatic invert detection is enabled by default. To disable it and use manual settings, use \texttt{--no\_auto\_invert} along with \texttt{--invert} or \texttt{--no\_invert}. The code file should be renamed to your student ID as required by the assignment.

\end{document}
